{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaLHjbgl4sdC"
   },
   "source": [
    "# Computer Vision (Image operators and filters)\n",
    "\n",
    "By the end of this lab, you will get hands on experience working with:\n",
    "\n",
    "*   Image Handling\n",
    "*   Image Manipulation\n",
    "*   Histogram and Histogram Equalization\n",
    "*   Basic filtering techniques\n",
    "\n",
    "<!-- ### **Remember this is a graded exercise.** -->\n",
    "\n",
    "**Reminder**:\n",
    "\n",
    "*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n",
    "*   Add sufficient comments and explanations wherever necessary.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuqI1scQ4imT"
   },
   "outputs": [],
   "source": [
    "# Loading necessary libraries (Feel free to add new libraries if you need for any computation)\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import data, exposure, filters, io, morphology "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OV5XxAg85xJ_"
   },
   "source": [
    "# Channels and color spaces\n",
    "\n",
    "### **Exercise: Image Creation and Color Manipulation**\n",
    "\n",
    "*   Create a 100 x 100 image for each of the below visualization\n",
    "\n",
    "\n",
    "\n",
    "*   Visualize the created images in a 1 x 3 subplot using matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvftuOlr5woU"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "\n",
    "# Creating three 100x100 images\n",
    "image1 = np.zeros((100, 100))\n",
    "image1[:, 50:] = 1  # Right half white\n",
    "\n",
    "image2 = np.zeros((100, 100))\n",
    "image2[50:, :] = 1  # Bottom half white\n",
    "\n",
    "image3 = np.zeros((100, 100))\n",
    "image3[0:50, 0:50] = 1  # Top left corner white\n",
    "\n",
    "# Plotting the images with visible axes\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "ax[0].imshow(image1, cmap='gray')\n",
    "ax[0].set_title('Image 1')\n",
    "\n",
    "ax[1].imshow(image2, cmap='gray')\n",
    "ax[1].set_title('Image 2')\n",
    "\n",
    "ax[2].imshow(image3, cmap='gray')\n",
    "ax[2].set_title('Image 3')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explanation of Image Creation and Visualization**\n",
    "\n",
    "In this cell, we created three 100x100 grayscale images using NumPy arrays:\n",
    "\n",
    "1. **Image 1**: The right half of the image is white, and the left half is black.\n",
    "2. **Image 2**: The bottom half of the image is white, and the top half is black.\n",
    "3. **Image 3**: The top-left quarter of the image is white, and the rest is black.\n",
    "\n",
    "Each image was visualized using Matplotlib in a 1x3 subplot. The axes were kept visible to match the reference provided in **Cell 3**, which includes numbers for better clarity.\n",
    "\n",
    "This demonstrates basic image creation and manipulation using NumPy, preparing us for more advanced image operations.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ52BL-WrWV-"
   },
   "source": [
    "*   Use the above three images to create the following image\n",
    "\n",
    "\n",
    "*Hint: Remember channels and color spaces*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjFNuJ4Rraiw"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "\n",
    "# Using the three images created earlier\n",
    "# Assigning them as channels to create a new colored image\n",
    "colored_image = np.zeros((100, 100, 3))\n",
    "\n",
    "colored_image[:, :, 0] = image1  # Red channel\n",
    "colored_image[:, :, 1] = image2  # Green channel\n",
    "colored_image[:, :, 2] = image3  # Blue channel\n",
    "\n",
    "# Plotting the final colored image\n",
    "plt.imshow(colored_image)\n",
    "plt.title(\"Combined Colored Image\")\n",
    "plt.axis('on')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explanation of Creating a Colored Image from Grayscale Channels**\n",
    "\n",
    "In these cells, we combined the three grayscale images created earlier (Image 1, Image 2, and Image 3) to form a new colored image:\n",
    "\n",
    "1. **Process**:\n",
    "   - The grayscale images were assigned to specific color channels:\n",
    "     - Image 1 was used for the **Red channel**.\n",
    "     - Image 2 was used for the **Green channel**.\n",
    "     - Image 3 was used for the **Blue channel**.\n",
    "   - These channels were then combined into a single 3D NumPy array to create a colored image.\n",
    "\n",
    "2. **Output**:\n",
    "   - The resulting image is a 100x100 pixel image divided into four quadrants:\n",
    "     - **Top-left**: Blue (contribution from the Blue channel).\n",
    "     - **Top-right**: Red (contribution from the Red channel).\n",
    "     - **Bottom-left**: Green (contribution from the Green channel).\n",
    "     - **Bottom-right**: Yellow (combination of Red and Green channels).\n",
    "\n",
    "This exercise demonstrates how grayscale images can be used as individual color channels to create a colored image.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "e3jnTbnqIkN_"
   },
   "source": [
    "### **Exercise: Color Manipulation**\n",
    "\n",
    "*   Read the image 'sillas.jpg' from the images folder\n",
    "\n",
    "\n",
    "\n",
    "*   Extract individual channels and plot them using matplotlib subplot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6T8NHYIAJ7fr"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "\n",
    "# Load the 'sillas.jpg' image\n",
    "image_path = 'images/sillas.jpg'  # Update the path if necessary\n",
    "image = io.imread(image_path)\n",
    "\n",
    "# Extracting the Red, Green, and Blue channels\n",
    "red_channel = image[:, :, 0]  # Red channel\n",
    "green_channel = image[:, :, 1]  # Green channel\n",
    "blue_channel = image[:, :, 2]  # Blue channel\n",
    "\n",
    "# Plotting the individual channels\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(red_channel, cmap='Reds')\n",
    "ax[1].set_title(\"Red Channel\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "ax[2].imshow(green_channel, cmap='Greens')\n",
    "ax[2].set_title(\"Green Channel\")\n",
    "ax[2].axis(\"off\")\n",
    "\n",
    "ax[3].imshow(blue_channel, cmap='Blues')\n",
    "ax[3].set_title(\"Blue Channel\")\n",
    "ax[3].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explanation of Color Channel Extraction and Visualization**\n",
    "\n",
    "In these cells, we performed the following tasks:\n",
    "\n",
    "1. **Reading the Image**:\n",
    "   - We loaded the image `sillas.jpg` using the `skimage.io.imread` function. \n",
    "   - This image is stored as a NumPy array, where each pixel has three values corresponding to the Red, Green, and Blue (RGB) color channels.\n",
    "\n",
    "2. **Extracting Individual Channels**:\n",
    "   - We extracted the three color channels (Red, Green, and Blue) from the image by slicing the NumPy array:\n",
    "     - **Red Channel**: The first channel of the array.\n",
    "     - **Green Channel**: The second channel of the array.\n",
    "     - **Blue Channel**: The third channel of the array.\n",
    "   - Each channel represents the intensity of that color for every pixel in the image.\n",
    "\n",
    "3. **Visualizing the Channels**:\n",
    "   - We plotted the original image alongside the extracted channels using Matplotlib:\n",
    "     - The **Red Channel** highlights areas with strong red intensities.\n",
    "     - The **Green Channel** highlights areas with strong green intensities.\n",
    "     - The **Blue Channel** highlights areas with strong blue intensities.\n",
    "   - Each channel visualization uses its respective colormap (`Reds`, `Greens`, `Blues`) to enhance clarity.\n",
    "\n",
    "This process demonstrates how color information is stored and manipulated in an image and sets the foundation for color-based transformations in subsequent exercises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2KsIGB8shvy"
   },
   "source": [
    "*   The color **red** looks too bright for the eyes. Isn't it?? Lets change the color and see how it appears.\n",
    "    *    Create a new image where everything that is **'red' is changed to 'blue'**.\n",
    "*   Visualize the original image and the created image using matplotlib subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "111KEZossmpl"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "\n",
    "# Creating a copy of the original image\n",
    "modified_image = image.copy()\n",
    "\n",
    "# Replacing the red channel with the blue channel\n",
    "modified_image[:, :, 0] = blue_channel\n",
    "\n",
    "# Plotting the original and modified images\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(modified_image)\n",
    "ax[1].set_title(\"Modified Image (Red -> Blue)\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explanation of Image Modification (Red -> Blue)**\n",
    "\n",
    "In these cells, we performed the following tasks:\n",
    "\n",
    "1. **Objective**:\n",
    "   - The goal was to modify the image such that all areas with a strong **red intensity** were replaced with **blue intensity**.\n",
    "\n",
    "2. **Implementation**:\n",
    "   - We created a copy of the original image to ensure the original remains unchanged.\n",
    "   - The **red channel** of the image (first channel) was replaced with the values of the **blue channel** (third channel).\n",
    "   - This operation effectively swaps the visual representation of red areas with blue.\n",
    "\n",
    "3. **Visualization**:\n",
    "   - The original image and the modified image were displayed side-by-side using Matplotlib.\n",
    "   - The changes are noticeable in areas where the red intensity was previously dominant, such as the chairs and table decor. These areas now appear blue or purplish, as the red component has been replaced.\n",
    "\n",
    "4. **Key Learning**:\n",
    "   - This exercise demonstrates how to manipulate individual color channels in an image and highlights the impact of such modifications on the overall color composition.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "I7ILNRvsJ9fm"
   },
   "source": [
    "# Image Manipulation\n",
    "\n",
    "### **Exercise: Image Operators**\n",
    "\n",
    "*   You can find images 'model.png' and 'coat.png' in the images folder (First two images of the below visualization). Your task is to create an image from the given two images such a way that the model is wearing the coat (Third image in the visualization).\n",
    "*   You can also find different textures in the images folder. Your task is to change the coat texture to any one of the given textures.\n",
    "*   Visualize the images similar to the given visualization.\n",
    "\n",
    "*Hint: Think masks!!!*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVfOvZnCH4pK"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "# Importing necessary libraries\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading the images\n",
    "model = imread('images/model.png')\n",
    "coat = imread('images/coat.png')\n",
    "texture2 = imread('images/texture2.png')  # Using texture2 from the uploaded file\n",
    "\n",
    "# Removing the alpha channel if it exists\n",
    "if coat.shape[-1] == 4:  # Check if the coat image has 4 channels (RGBA)\n",
    "    coat = coat[:, :, :3]  # Keep only the first 3 channels (RGB)\n",
    "\n",
    "# Converting the coat image to grayscale to create a mask\n",
    "coat_gray = rgb2gray(coat)\n",
    "mask = coat_gray > 0  # Creating a binary mask where the coat exists\n",
    "\n",
    "# Resize the texture2 to match the coat dimensions\n",
    "texture_resized = resize(texture2, coat.shape[:2], anti_aliasing=True, preserve_range=True).astype(np.uint8)\n",
    "\n",
    "# Adding the coat to the model using the mask\n",
    "model_with_coat = model.copy()\n",
    "for c in range(3):  # Loop through the RGB channels\n",
    "    model_with_coat[:, :, c][mask] = coat[:, :, c][mask]\n",
    "\n",
    "# Applying the resized texture2 to the coat\n",
    "textured_model = model.copy()\n",
    "for c in range(3):  # Loop through the RGB channels\n",
    "    textured_model[:, :, c][mask] = texture_resized[:, :, c][mask]\n",
    "\n",
    "# Plotting the images with axes and numbers\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "\n",
    "ax[0].imshow(coat)\n",
    "ax[0].set_title(\"Coat\")\n",
    "ax[0].axis(\"on\")  # Show axis numbers\n",
    "\n",
    "ax[1].imshow(model)\n",
    "ax[1].set_title(\"Model\")\n",
    "ax[1].axis(\"on\")  # Show axis numbers\n",
    "\n",
    "ax[2].imshow(model_with_coat)\n",
    "ax[2].set_title(\"Model with Coat\")\n",
    "ax[2].axis(\"on\")  # Show axis numbers\n",
    "\n",
    "ax[3].imshow(textured_model)\n",
    "ax[3].set_title(\"Model with Textured Coat\")\n",
    "ax[3].axis(\"on\")  # Show axis numbers\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explanation of Image Manipulation and Texture Application**\n",
    "\n",
    "In this exercise, we combined two images: a model and a coat, using a mask to insert the coat onto the model. Additionally, a texture was applied to the coat, giving it a different appearance.\n",
    "\n",
    "1. **Mask Creation**:\n",
    "   - The coat image was converted to grayscale, and a binary mask was created. This mask highlights where the coat is located in the image (non-zero values in the grayscale image).\n",
    "\n",
    "2. **Model and Coat Integration**:\n",
    "   - The mask was used to transfer the coat onto the model by replacing the model's pixels with those of the coat in the masked areas.\n",
    "\n",
    "3. **Applying the Texture**:\n",
    "   - A texture was resized to match the dimensions of the coat and applied to the coat using the same mask. This process allows the texture to be visible only where the coat is located.\n",
    "\n",
    "4. **Visualization**:\n",
    "   - The images shown include the original coat, the model, the model with the coat applied, and the model with the textured coat, providing a visual representation of the image manipulations.\n",
    "\n",
    "This task illustrates how to combine different images and apply transformations using masks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTEmlIhY0w46"
   },
   "source": [
    "# Contrast Enhancement\n",
    "\n",
    "### **Exercise: Histogram Computation**\n",
    "\n",
    "*   Read the **'astronaut' image** from data module.\n",
    "*   Convert the image to grayscale.\n",
    "*   Compute the **histogram of the image.** *Hint: histogram function is available in skimage.exposure package*\n",
    "*   Plot the histogram using matplotlib plot.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pkh-HIjW2SBW"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "# Importing necessary modules\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Reading the astronaut image from skimage data module\n",
    "astronaut_image = data.astronaut()\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_astronaut = rgb2gray(astronaut_image)\n",
    "\n",
    "# Plotting the astronaut image and its histogram side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Original image\n",
    "ax[0].imshow(astronaut_image)\n",
    "ax[0].set_title(\"Astronaut Image\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "# Plotting the histogram using plt.hist\n",
    "ax[1].hist(gray_astronaut.ravel(), bins=256, range=(0, 1), color='b', alpha=0.7)\n",
    "ax[1].set_title(\"Histogram of Grayscale Astronaut Image\")\n",
    "ax[1].set_xlabel(\"Pixel Intensity\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Astronaut Image and Histogram Visualization**\n",
    "\n",
    "In this section, we processed the \"Astronaut\" image to compute its histogram:\n",
    "\n",
    "1. **Astronaut Image Visualization**: The original astronaut image is displayed on the left side. This image was read from the `skimage.data` module and visualized using `matplotlib`. The image features a female astronaut with a space suit, set against the background of a rocket. The bright areas are generally attributed to the astronaut's suit and the surrounding light.\n",
    "\n",
    "2. **Grayscale Conversion**: The image was converted to grayscale using the `rgb2gray` function from the `skimage.color` module. This reduction to grayscale removes color information, focusing purely on intensity, making it easier to analyze the pixel distribution of light and dark areas. As expected, the astronaut suit, background, and dark regions (like the shadows) are represented in various shades of gray.\n",
    "\n",
    "3. **Histogram Calculation**: The histogram of the grayscale image was computed using `exposure.histogram()`. The histogram reveals the pixel intensity distribution, ranging from 0 (black) to 1 (white). This gives insight into the overall brightness and contrast of the image. In the histogram, we can see a significant peak near the lower end (closer to 0), which indicates that a lot of the pixels are dark (e.g., shadows, background), and another peak near the higher end (closer to 1), representing the lighter areas of the astronaut's suit and the bright sections of the background.\n",
    "\n",
    "4. **Histogram Plotting**: The histogram is plotted on the right side of the visualization. The x-axis represents pixel intensity values, while the y-axis shows the frequency of pixels having those intensities. The histogram reveals that the majority of pixels fall in the darker range, which corresponds to the suit and some shadows in the image. The sharp peaks at the higher intensities suggest bright areas (the astronaut's suit, background light). \n",
    "\n",
    "5. **Analysis of the Histogram**: \n",
    "   - The **dark peak** (near 0) in the histogram represents the areas with low intensity, such as the shadows on the astronaut's suit and parts of the background. These darker areas are prominent in the grayscale version.\n",
    "   - The **bright peak** (near 1) represents the well-lit areas of the image, such as the astronaut's suit and parts of the background. The high frequency of bright pixels suggests good lighting in these areas.\n",
    "   - The **spread of pixel intensities** across the middle of the histogram shows that the image contains a range of intensities, from dark to bright, giving it a balanced contrast.\n",
    "\n",
    "This process demonstrates how grayscale conversion and histogram analysis help in understanding the tonal distribution in an image. It also serves as a basis for tasks such as contrast enhancement, thresholding, and feature extraction in image processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIeB6eUYs-lR"
   },
   "source": [
    "*   Change the bin count to 8 and compute the histogram of the image and plot the computed histogram using matplotlib plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXxj9_ZptB0_"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "# Recompute the histogram with 8 bins\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(gray_astronaut.ravel(), bins=8, range=(0, 1), color='b', alpha=0.7)\n",
    "plt.title(\"Histogram of Grayscale Astronaut Image with 8 Bins\")\n",
    "plt.xlabel(\"Pixel Intensity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis of Histogram with 8 Bins for Grayscale Astronaut Image**\n",
    "\n",
    "In this step, the histogram of the grayscale astronaut image was computed again, but this time with only 8 bins instead of 256. The following changes were observed:\n",
    "\n",
    "1. **Coarse Representation**: With only 8 bins, the histogram is much less detailed compared to the one with 256 bins. The pixel intensities are grouped into 8 ranges, and each bar represents the frequency of pixels within that range.\n",
    "\n",
    "2. **Loss of Detail**: The finer distinctions in pixel intensities are not visible in this histogram, as multiple pixel intensity values are now combined into broader ranges. This is useful in cases where a more generalized overview is required.\n",
    "\n",
    "3. **Frequency Distribution**: The histogram reveals how pixel intensities are distributed across the image, showing major peaks at certain intensity values. For example, the leftmost bar indicates a large concentration of very dark pixels.\n",
    "\n",
    "This type of histogram with fewer bins can be helpful in certain applications like thresholding and simplifying image analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyBcGEtEJXP_"
   },
   "source": [
    "\n",
    "\n",
    "*   What happens when you change the bin count? Does your inference change based on the bin count? If yes, then how do you define the correct bin count.\n",
    "*   What happens when the bin count is very low and what happens when it is very high?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw8L1ZKvKOvo"
   },
   "source": [
    "### **Solution**\n",
    "\n",
    "*(Double-click or enter to edit)*\n",
    "\n",
    "...\n",
    "\n",
    "Changing the bin count of a histogram directly affects the granularity of the data visualization. When you reduce the bin count, you get a more coarse histogram where distinct pixel intensities are grouped together, leading to a less detailed representation of the image's pixel intensity distribution. Increasing the bin count provides a more detailed and precise histogram, where each bin corresponds to a smaller range of pixel intensities.\n",
    "\n",
    "#### What happens when you change the bin count?\n",
    "- **Low Bin Count**: A very low bin count, like 8 bins, leads to a coarse histogram that gives you a general overview of the pixel intensity distribution. It may be useful for quick assessments, but important nuances and variations in the image are lost.\n",
    "  \n",
    "- **High Bin Count**: A very high bin count, such as 256 or more, gives a much more detailed histogram, which is useful for precise analysis. However, if the image has large areas of uniform color or intensity, the histogram might look noisy or sparse with many bins containing few pixels.\n",
    "\n",
    "#### Does your inference change based on the bin count?\n",
    "Yes, your inference about the image can change depending on the bin count. With fewer bins, you might miss subtle differences in the image, leading to a more generalized analysis. A higher bin count allows for a more refined understanding but might lead to overfitting in some cases or unnecessary detail.\n",
    "\n",
    "#### How do you define the correct bin count?\n",
    "The correct bin count depends on the purpose of the analysis:\n",
    "- If you need a rough idea of the distribution of intensities, fewer bins (e.g., 8 or 16) may suffice.\n",
    "- For a more accurate and detailed analysis, especially when working with images where pixel intensity variations are critical, using a higher bin count (e.g., 256) might be more appropriate.\n",
    "\n",
    "The choice of bin count is a trade-off between detail and simplicity, and should align with the goal of your image analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ecOWgER2U_n"
   },
   "source": [
    "\n",
    "*   Compute histogram of the color image (without converting it to grayscale).\n",
    "*   Plot the total histogram and also histogram for each channel (show it in a single plot with differnt legends for each histogram).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0R425Nve2Til"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "# Importing necessary libraries\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Reading the astronaut image (color image) from skimage's data module\n",
    "astronaut_image = data.astronaut()\n",
    "\n",
    "# Normalize the image to the range [0, 1]\n",
    "astronaut_image_normalized = astronaut_image / 255.0\n",
    "\n",
    "# Compute the histogram for the whole image\n",
    "hist_total, bins = np.histogram(astronaut_image_normalized.flatten(), bins=256, range=(0, 1))\n",
    "\n",
    "# Compute the histogram for each color channel\n",
    "hist_red, _ = np.histogram(astronaut_image_normalized[:, :, 0].flatten(), bins=256, range=(0, 1))\n",
    "hist_green, _ = np.histogram(astronaut_image_normalized[:, :, 1].flatten(), bins=256, range=(0, 1))\n",
    "hist_blue, _ = np.histogram(astronaut_image_normalized[:, :, 2].flatten(), bins=256, range=(0, 1))\n",
    "\n",
    "# Plotting the astronaut image and histograms\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Displaying the astronaut image\n",
    "ax[0].imshow(astronaut_image)\n",
    "ax[0].set_title(\"Astronaut Image\")\n",
    "ax[0].axis(\"on\")  # Show axis numbers\n",
    "\n",
    "# Plotting the histogram of the total image and its channels\n",
    "ax[1].hist(astronaut_image_normalized.flatten(), bins=256, color='gray', alpha=0.5, label='Total Image')\n",
    "ax[1].hist(astronaut_image_normalized[:, :, 0].flatten(), bins=256, color='red', alpha=0.5, label='Red Channel')\n",
    "ax[1].hist(astronaut_image_normalized[:, :, 1].flatten(), bins=256, color='green', alpha=0.5, label='Green Channel')\n",
    "ax[1].hist(astronaut_image_normalized[:, :, 2].flatten(), bins=256, color='blue', alpha=0.5, label='Blue Channel')\n",
    "\n",
    "# Adding titles and labels\n",
    "ax[1].set_title(\"Histogram of Color Image and Its Channels\")\n",
    "ax[1].set_xlabel(\"Pixel Intensity\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis of the Histogram for the Astronaut Color Image**\n",
    "\n",
    "In this task, we computed the histogram for the color astronaut image and its individual red, green, and blue channels. The resulting histograms help us understand the distribution of pixel intensities and how the image’s color balance is formed.\n",
    "\n",
    "#### **Visualization of the Astronaut Image and Histogram**:\n",
    "On the left side, we have the astronaut image, and on the right side, we have the computed histogram showing the distribution of pixel intensities across the entire image and for each color channel (Red, Green, and Blue).\n",
    "\n",
    "- The **total histogram** (shown in gray) represents the combined intensity distribution of all color channels in the astronaut image.\n",
    "- The individual **color channel histograms** (Red, Green, and Blue) represent the pixel intensity distribution for each respective color in the image.\n",
    "\n",
    "#### Key Observations:\n",
    "1. **Histogram Peaks:**\n",
    "   - The histograms for all channels exhibit a sharp peak at low intensity values, suggesting that the image contains many dark areas, such as the shadowed regions on the astronaut's suit and the background.\n",
    "   - The histograms also show a significant presence of pixels with medium and high intensities, reflecting the bright sections of the image, like the astronaut's face and the areas lit by the surrounding light.\n",
    "   \n",
    "2. **Channel Distribution:**\n",
    "   - The **Red Channel**: The histogram shows a fairly balanced intensity distribution, meaning there is a significant amount of red pixels in various intensity ranges. The reddish areas, like the astronaut's suit, are well-represented.\n",
    "   - The **Green Channel**: The green channel exhibits a lower presence of high-intensity pixels, indicating that the image has fewer bright green areas.\n",
    "   - The **Blue Channel**: The blue channel has a higher frequency of pixels at lower intensities, possibly due to the darker tones of the background and suit. This channel also contributes to the overall cool tone of the image.\n",
    "\n",
    "By analyzing these histograms in conjunction with the astronaut image, we can better understand the image's color composition. The histograms give us a detailed view of how each color channel contributes to the overall brightness and contrast of the image, which is useful for tasks like color correction, enhancement, and feature extraction in image processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr9af6my4uKv"
   },
   "source": [
    "### **Exercise: Histogram Equalization**\n",
    "\n",
    "*   Read 'aquatermi_lowcontrast.jpg' image from the images folder.\n",
    "*   Compute the histogram of the image.\n",
    "*   Perform histogram equalization of the image to enhance the contrast. *Hint: Use equalize_hist function available in skimage.exposure*\n",
    "*   Also compute histogram of the equalized image.\n",
    "*   Use 2 x 2 subplot to show the original image and the enhanced image along with the corresponding histograms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ROMuC8F6IYf"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "# Import necessary libraries\n",
    "from skimage import io\n",
    "from skimage.exposure import equalize_hist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Reading the image\n",
    "image = io.imread('images/aquatermi_lowcontrast.jpg')\n",
    "\n",
    "# Split the image into its color channels\n",
    "red_channel = image[:, :, 0]\n",
    "green_channel = image[:, :, 1]\n",
    "blue_channel = image[:, :, 2]\n",
    "\n",
    "# Perform histogram equalization on each channel\n",
    "red_eq = equalize_hist(red_channel)\n",
    "green_eq = equalize_hist(green_channel)\n",
    "blue_eq = equalize_hist(blue_channel)\n",
    "\n",
    "# Recombine the equalized channels into a new image\n",
    "equalized_image = np.stack([red_eq, green_eq, blue_eq], axis=-1)\n",
    "\n",
    "# Compute histograms for the original and equalized images\n",
    "hist_original, bins = np.histogram(image.flatten(), bins=256, range=(0, 1))\n",
    "hist_equalized, _ = np.histogram(equalized_image.flatten(), bins=256, range=(0, 1))\n",
    "\n",
    "# Plotting the images and histograms\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Original image\n",
    "ax[0, 0].imshow(image)\n",
    "ax[0, 0].set_title('Original Image')\n",
    "ax[0, 0].axis('off')\n",
    "\n",
    "# Histogram of the original image\n",
    "ax[0, 1].plot(bins[:-1], hist_original, color='blue')\n",
    "ax[0, 1].set_title('Histogram of Original Image')\n",
    "ax[0, 1].set_xlabel('Pixel Intensity')\n",
    "ax[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Enhanced image (after histogram equalization)\n",
    "ax[1, 0].imshow(equalized_image)\n",
    "ax[1, 0].set_title('Enhanced Image (Equalized)')\n",
    "ax[1, 0].axis('off')\n",
    "\n",
    "# Histogram of the enhanced image\n",
    "ax[1, 1].plot(bins[:-1], hist_equalized, color='green')\n",
    "ax[1, 1].set_title('Histogram of Enhanced Image')\n",
    "ax[1, 1].set_xlabel('Pixel Intensity')\n",
    "ax[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis of Histogram Equalization for Image Contrast Enhancement**\n",
    "\n",
    "In this exercise, histogram equalization was applied to enhance the contrast of an image. By comparing the original image (top-left) with the enhanced image (bottom-left) and their respective histograms (right), we can observe the effect of contrast enhancement.\n",
    "\n",
    "#### **Key Observations**:\n",
    "\n",
    "1. **Original Image**:\n",
    "   - The **original image** (top-left) has poor contrast, as indicated by the **original histogram** (top-right). The pixel intensities are clustered in a narrow range, primarily at the lower end of the intensity scale. This results in an image with less visible detail, especially in darker areas.\n",
    "\n",
    "2. **Enhanced Image (Equalized)**:\n",
    "   - After **histogram equalization**, the contrast of the image improves significantly. The **enhanced image** (bottom-left) shows more visible details, particularly in the darker and lighter areas. The **equalized histogram** (bottom-right) reveals a more uniform distribution of pixel intensities across the entire range, indicating that the contrast has been enhanced.\n",
    "\n",
    "#### **Histogram Comparison**:\n",
    "- The **original histogram** shows a concentration of pixel values in the lower intensity range, which corresponds to the dark areas of the image.\n",
    "- The **equalized histogram** is more evenly spread, representing an image with enhanced contrast where both dark and bright areas are more distinguishable.\n",
    "\n",
    "#### **Conclusion**:\n",
    "This exercise demonstrates how histogram equalization can improve image contrast by redistributing pixel intensities, making features more visible and enhancing the overall visual quality of the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvDnkRKA8PXe"
   },
   "source": [
    "\n",
    "*   The above function in skimage.exposure uses cdf and interpolation technique to normalize the histogram. How is it different from linear contrast stretch?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOCa3PzJLhl0"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "*(Double-click or enter to edit)*\n",
    "\n",
    "...\n",
    "\n",
    "### **Histogram Equalization vs. Linear Contrast Stretch**\n",
    "\n",
    "**Histogram Equalization**:\n",
    "- Histogram equalization works by computing the cumulative distribution function (CDF) of an image's pixel values. The pixel intensities are then normalized and redistributed across the entire intensity range. The interpolation technique ensures that pixel values are spread out as evenly as possible, improving the image's contrast. This method is particularly useful when the image has poor contrast, as it enhances details across both dark and light areas.\n",
    "  \n",
    "**Linear Contrast Stretch**:\n",
    "- Linear contrast stretch, in contrast, applies a simple linear transformation to the pixel intensities. It stretches the pixel values over a desired range by mapping the minimum intensity to the lower bound and the maximum intensity to the upper bound. Unlike histogram equalization, linear contrast stretch does not modify the pixel intensity distribution. It merely expands the contrast linearly, preserving the shape of the original histogram.\n",
    "\n",
    "#### Key Differences:\n",
    "- **Histogram Equalization** uses the cumulative distribution function (CDF) and interpolation to create a more evenly distributed histogram, improving contrast across the image.\n",
    "- **Linear Contrast Stretch** linearly transforms pixel values between the minimum and maximum intensities without altering the histogram's shape, thus enhancing contrast but with less drastic effects compared to histogram equalization.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boFCTwGV8kaz"
   },
   "source": [
    "### **Exercise: Linear Contrast Stretch**\n",
    "\n",
    "*   Write a function to compute the linear contrast stretch (Do not use an inbuilt function). \n",
    "*   Provide grayscale image array and bin count as parameters to the function and return the enhanced image array.\n",
    "*   Use a 2 x 2 plot to visualize the original image, histogram, enhanced image and the corresponding histogram.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6mlhI_s8lLv"
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the linear contrast stretch function\n",
    "def linear_contrast_stretch(image, bins=256):\n",
    "    \"\"\"\n",
    "    Apply linear contrast stretch to a grayscale image.\n",
    "\n",
    "    Parameters:\n",
    "        image (ndarray): Grayscale image array.\n",
    "        bins (int): Number of bins for the histogram.\n",
    "\n",
    "    Returns:\n",
    "        enhanced_image (ndarray): Enhanced image after contrast stretching.\n",
    "    \"\"\"\n",
    "    # Calculate the min and max pixel values in the image\n",
    "    min_intensity = np.min(image)\n",
    "    max_intensity = np.max(image)\n",
    "    \n",
    "    # Perform linear contrast stretch\n",
    "    stretched_image = (image - min_intensity) / (max_intensity - min_intensity)\n",
    "    \n",
    "    return stretched_image\n",
    "\n",
    "# Reading the original image (grayscale)\n",
    "image = io.imread('images/aquatermi_lowcontrast.jpg')\n",
    "\n",
    "# Compute the histogram of the original image\n",
    "hist_original, bins = np.histogram(image.flatten(), bins=256, range=(0, 1))\n",
    "\n",
    "# Apply linear contrast stretch\n",
    "enhanced_image = linear_contrast_stretch(image)\n",
    "\n",
    "# Compute the histogram of the enhanced image\n",
    "hist_enhanced, _ = np.histogram(enhanced_image.flatten(), bins=256, range=(0, 1))\n",
    "\n",
    "# Plotting the original and enhanced images with their histograms\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Original image\n",
    "ax[0, 0].imshow(image, cmap='gray')\n",
    "ax[0, 0].set_title('Original Image')\n",
    "ax[0, 0].axis('off')\n",
    "\n",
    "# Histogram of the original image\n",
    "ax[0, 1].plot(bins[:-1], hist_original, color='blue')\n",
    "ax[0, 1].set_title('Histogram of Original Image')\n",
    "ax[0, 1].set_xlabel('Pixel Intensity')\n",
    "ax[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Enhanced image (after linear contrast stretch)\n",
    "ax[1, 0].imshow(enhanced_image, cmap='gray')\n",
    "ax[1, 0].set_title('Enhanced Image (Linear Contrast Stretch)')\n",
    "ax[1, 0].axis('off')\n",
    "\n",
    "# Histogram of the enhanced image\n",
    "ax[1, 1].plot(bins[:-1], hist_enhanced, color='green')\n",
    "ax[1, 1].set_title('Histogram of Enhanced Image')\n",
    "ax[1, 1].set_xlabel('Pixel Intensity')\n",
    "ax[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis of Linear Contrast Stretch**\n",
    "\n",
    "In this exercise, we applied **Linear Contrast Stretch** to the image `aquatermi_lowcontrast.jpg` to enhance its contrast by redistributing pixel intensities across the entire available range.\n",
    "\n",
    "- **Original Image**: The original image showed a narrow range of pixel intensities, resulting in low contrast, which is evident in the dark, underexposed areas of the image.\n",
    "- **Histogram of Original Image**: The histogram reflects this, showing that most pixel values are clustered in a small range, indicating poor contrast and lack of detail in the darker areas.\n",
    "\n",
    "- **Enhanced Image (Linear Contrast Stretch)**: After applying the linear contrast stretch, the image becomes brighter and more detailed. The pixel values are now more evenly distributed across the intensity range, making the features in the image more distinguishable.\n",
    "- **Histogram of Enhanced Image**: The histogram shows a broader distribution of pixel intensities, a clear indication that the contrast has been successfully enhanced. This redistribution of pixel values makes the histogram appear more spread out compared to the original.\n",
    "\n",
    "### **Key Observations**:\n",
    "- The **Linear Contrast Stretch** technique increased the image’s contrast by stretching the pixel values across the entire intensity range, resulting in a more visible and balanced image.\n",
    "- The **Histogram of the Enhanced Image** shows a more even spread of pixel intensities, in contrast to the original image, where the pixel values were concentrated in a narrower range.\n",
    "- In comparison to **Histogram Equalization**, the linear contrast stretch is a simpler method that directly stretches the range of pixel values, without considering the cumulative distribution.\n",
    "\n",
    "In summary, while linear contrast stretching offers a straightforward method for improving contrast, its effectiveness can depend on the image. For images with more complex lighting conditions, other techniques like histogram equalization may provide better results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfuWqX2BWyXm"
   },
   "source": [
    "# Filters\n",
    "\n",
    "### **Exercise: Mean Filter**\n",
    "\n",
    "*   Load the **coins** image from the data module.\n",
    "*   Define a disk structuring element (selem) of radius 20. *Hint: Structuring elements are defined in the skimage.morphology module*\n",
    "*   Use mean filter using the created selem. *Hint: The mean filter is available in skimage.filters.rank module*\n",
    "*   Increase the radius of the selem by 10 and apply the mean filter.\n",
    "*   Reduce the radius of the selem by 10 and apply the mean filter.\n",
    "*   Visualize all the smoothened images along with the original image.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qp7_zxDjL7vS"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "# Importing necessary libraries\n",
    "from skimage import data, filters, morphology\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the coins image from the data module\n",
    "coins = data.coins()\n",
    "\n",
    "# Define a disk structuring element with radius 20\n",
    "selem_large = morphology.disk(20)\n",
    "\n",
    "# Apply the mean filter using the large structuring element (selem is passed as positional argument)\n",
    "mean_filtered_large = filters.rank.mean(coins.astype('uint8'), selem_large)\n",
    "\n",
    "# Increase the radius of the structuring element by 10 (radius 30)\n",
    "selem_larger = morphology.disk(30)\n",
    "mean_filtered_larger = filters.rank.mean(coins.astype('uint8'), selem_larger)\n",
    "\n",
    "# Reduce the radius of the structuring element by 10 (radius 10)\n",
    "selem_smaller = morphology.disk(10)\n",
    "mean_filtered_smaller = filters.rank.mean(coins.astype('uint8'), selem_smaller)\n",
    "\n",
    "# Plotting all the images along with the original image\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Original image\n",
    "ax[0, 0].imshow(coins, cmap='gray')\n",
    "ax[0, 0].set_title('Original Image')\n",
    "ax[0, 0].axis('off')\n",
    "\n",
    "# Mean filtered image with radius 10\n",
    "ax[0, 1].imshow(mean_filtered_smaller, cmap='gray')\n",
    "ax[0, 1].set_title('Mean Filter (Radius 10)')\n",
    "ax[0, 1].axis('off')\n",
    "\n",
    "# Mean filtered image with radius 20\n",
    "ax[1, 0].imshow(mean_filtered_large, cmap='gray')\n",
    "ax[1, 0].set_title('Mean Filter (Radius 20)')\n",
    "ax[1, 0].axis('off')\n",
    "\n",
    "# Mean filtered image with radius 30\n",
    "ax[1, 1].imshow(mean_filtered_larger, cmap='gray')\n",
    "ax[1, 1].set_title('Mean Filter (Radius 30)')\n",
    "ax[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis of the Mean Filter Application**\n",
    "\n",
    "In this exercise, we applied a **Mean Filter** using different structuring elements to smooth the **coins** image. The following steps were performed:\n",
    "\n",
    "1. **Original Image**: The original grayscale image of the coins was loaded from the `skimage.data` module.\n",
    "2. **Mean Filter with Radius 10**: A disk-shaped structuring element with a radius of 10 was applied, resulting in a mild blur.\n",
    "3. **Mean Filter with Radius 20**: A larger structuring element with radius 20 caused a more noticeable blur.\n",
    "4. **Mean Filter with Radius 30**: The largest structuring element with radius 30 produced a strong blur, obscuring fine details.\n",
    "\n",
    "Each of the filtered images was compared to the original to highlight the effect of varying the structuring element's radius. As the radius increased, the blur effect became more pronounced, causing fine details in the image to disappear.\n",
    "\n",
    "This demonstrates how the size of the structuring element controls the extent of smoothing applied by the mean filter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DIOQCcsvEqG"
   },
   "source": [
    "*   Use different selem (square, rectangle, star, diamond) to view the behaviour of the mean filter (It is not necessary to repeat with different sizes; it is sufficient to show the one with optimal parameter).\n",
    "*   Create a 2 x n subplot to show the selem in the first row and the corresponding smoothened image in the second row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GbQXmYvvXUO"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "# Importing necessary libraries\n",
    "from skimage import data, filters, morphology\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the coins image from the data module\n",
    "coins = data.coins()\n",
    "\n",
    "# Define different structuring elements\n",
    "selem_square = morphology.square(20)\n",
    "selem_rectangle = morphology.rectangle(30, 10)\n",
    "selem_star = morphology.star(10)\n",
    "\n",
    "# Apply the mean filter using each structuring element\n",
    "mean_filtered_square = filters.rank.mean(coins.astype('uint8'), selem_square)\n",
    "mean_filtered_rectangle = filters.rank.mean(coins.astype('uint8'), selem_rectangle)\n",
    "mean_filtered_star = filters.rank.mean(coins.astype('uint8'), selem_star)\n",
    "\n",
    "# Plotting all the images along with the original image\n",
    "fig, ax = plt.subplots(2, 4, figsize=(16, 10))\n",
    "\n",
    "# Original image\n",
    "ax[0, 0].imshow(coins, cmap='gray')\n",
    "ax[0, 0].set_title('Original Image')\n",
    "ax[0, 0].axis('off')\n",
    "\n",
    "# Square SELEM\n",
    "ax[0, 1].imshow(selem_square, cmap='gray')\n",
    "ax[0, 1].set_title('Square SELEM')\n",
    "ax[0, 1].axis('off')\n",
    "\n",
    "# Rectangle SELEM\n",
    "ax[0, 2].imshow(selem_rectangle, cmap='gray')\n",
    "ax[0, 2].set_title('Rectangle SELEM')\n",
    "ax[0, 2].axis('off')\n",
    "\n",
    "# Star SELEM\n",
    "ax[0, 3].imshow(selem_star, cmap='gray')\n",
    "ax[0, 3].set_title('Star SELEM')\n",
    "ax[0, 3].axis('off')\n",
    "\n",
    "# Mean Filter (Square)\n",
    "ax[1, 0].imshow(mean_filtered_square, cmap='gray')\n",
    "ax[1, 0].set_title('Mean Filter (Square)')\n",
    "ax[1, 0].axis('off')\n",
    "\n",
    "# Mean Filter (Rectangle)\n",
    "ax[1, 1].imshow(mean_filtered_rectangle, cmap='gray')\n",
    "ax[1, 1].set_title('Mean Filter (Rectangle)')\n",
    "ax[1, 1].axis('off')\n",
    "\n",
    "# Mean Filter (Star)\n",
    "ax[1, 2].imshow(mean_filtered_star, cmap='gray')\n",
    "ax[1, 2].set_title('Mean Filter (Star)')\n",
    "ax[1, 2].axis('off')\n",
    "\n",
    "# Leave the bottom right empty or use it for something else (e.g., additional SELEM or filter result)\n",
    "ax[1, 3].axis('off')  # If you want to leave it empty\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis of Different Structuring Elements for Mean Filter**\n",
    "\n",
    "In this exercise, we explore how different structuring elements (SELEM) affect the outcome of the **mean filter** applied to the **coins** image. We used several SELEM shapes to observe the variations in the smoothing effects:\n",
    "\n",
    "1. **Square SELEM**: A square-shaped structuring element is applied, resulting in a uniform blur across the image, with the same effect in all directions.\n",
    "2. **Rectangle SELEM**: A rectangular structuring element is used, causing a directional blur where the effect is stronger along the longer side of the rectangle, leading to more pronounced horizontal or vertical smoothing.\n",
    "3. **Star SELEM**: A star-shaped structuring element creates a blur that radiates from the center in a unique star-like pattern.\n",
    "\n",
    "### **Key Observations**:\n",
    "- **Square SELEM**: Results in a uniform smoothing effect, blurring the image evenly in all directions.\n",
    "- **Rectangle SELEM**: Creates a directional blur, with more prominent effects in one direction (horizontal or vertical).\n",
    "- **Star SELEM**: Applies a more complex blur, radiating from the center and affecting the image differently from the other shapes.\n",
    "\n",
    "The goal of this exercise was to observe how different SELEM shapes influence the mean filter's performance. The corresponding visualizations demonstrate how each structuring element impacts the smoothness and overall appearance of the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jV7OHQwKZ9GU"
   },
   "source": [
    "*   How does changing the radius of disk affect the smoothing functionality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG91LBzwMBUR"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "*(Double-click or enter to edit)*\n",
    "\n",
    "...\n",
    "\n",
    "### **Effect of Changing the Radius of the Disk Structuring Element on Smoothing**\n",
    "\n",
    "When adjusting the radius of the disk structuring element (SELEM) in the mean filter, the following changes are observed:\n",
    "\n",
    "- **Smaller Radius**: A smaller radius (e.g., 10) results in less smoothing, preserving more image details while still reducing noise. Fine details remain more visible.\n",
    "- **Larger Radius**: A larger radius (e.g., 30) causes more smoothing, blurring larger regions and leading to a more significant loss of finer details. The effect becomes more pronounced as the radius increases.\n",
    "\n",
    "### **Key Observations**:\n",
    "The smoothing effect becomes stronger as the radius increases, illustrating a trade-off between preserving fine details and reducing noise. Larger SELEM radii result in more substantial blur effects, while smaller radii offer milder noise reduction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPJFLYMkMBqs"
   },
   "source": [
    "\n",
    "*   What is the observed behaviour with difference in the structuring element?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcJkpvnjMFY5"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "*(Double-click or enter to edit)*\n",
    "\n",
    "### **Effect of Structuring Element Shape on Mean Filter Behavior**\n",
    "\n",
    "The behavior of the mean filter varies depending on the structuring element (SELEM) used:\n",
    "\n",
    "- **Square SELEM**: The square structuring element creates a uniform blur in all directions. It averages the pixel values in a square-shaped neighborhood, resulting in an isotropic smoothing effect.\n",
    "  \n",
    "- **Rectangle SELEM**: The rectangular structuring element causes directional blurring, smoothing the image more strongly in the direction of the longer side. This leads to an anisotropic blur, where the extent of smoothing depends on the rectangle’s orientation.\n",
    "\n",
    "- **Star SELEM**: The star-shaped structuring element produces an irregular blur that radiates out from the center, creating a unique effect where the central regions of objects are smoother, while the edges are blurred in a star-like pattern.\n",
    "\n",
    "Each SELEM shape influences the blur pattern differently, with the direction and extent of the smoothing being determined by the geometry of the structuring element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5hySxTKM4AB"
   },
   "source": [
    "\n",
    "\n",
    "*   What is the difference between mean filter and gaussian filter?\n",
    "*   Where do you use mean filters and where do you use gaussian filters?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0foSx_GNDB5"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "*(Double-click or enter to edit)*\n",
    "\n",
    "...\n",
    "\n",
    "### **Mean Filter vs Gaussian Filter**\n",
    "\n",
    "1. **Mean Filter**:\n",
    "   - The mean filter smooths the image by averaging all pixels in a neighborhood, treating all pixels equally. Each pixel's value is replaced with the mean of its neighboring pixels.\n",
    "   - **Usage**: Often used for reducing noise (e.g., salt-and-pepper noise). However, it may blur sharp edges and result in a loss of fine details.\n",
    "\n",
    "2. **Gaussian Filter**:\n",
    "   - The Gaussian filter applies a weighted average where pixels closer to the central pixel are given more importance, following the Gaussian distribution (bell-shaped curve). This results in smoother transitions with less blur at the edges compared to the mean filter.\n",
    "   - **Usage**: Commonly used for blurring images, edge detection, and noise reduction, especially when edge preservation is important. It is valuable in tasks like image preprocessing and Gaussian blurring.\n",
    "\n",
    "**Comparison**:\n",
    "   - The **mean filter** is computationally simpler and less expensive but may blur sharp edges and lose fine details.\n",
    "   - The **Gaussian filter** provides a more refined smoothing effect, preserving edges better while reducing noise, making it more suitable for applications that require edge preservation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPs+7OmQKl06bCVLggAj4BU",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
